# 神经网络与深度学习

## 参考资料

[神经网络与深度学习--丘锡鹏](https://nndl.github.io/)

## 机器学习基础

### 第一章 绪论

#### 简谈深度学习(Deep Learning)

+ 定义：

  ​	从有限样例中通过算法总结出一般性的规律，并可以应用到新的未知数据上。

+ 实现：

  ​	通过一个或多个线性或非线性的组件构成一个完整的模型，输入的数据通过这些组件进行加工，最后得出结果。

+ 挑战：

  ​	贡献度分配问题(Credit Assignment Problem, CAP):

  ​	在深度学习中，每个组件对输出结果的贡献是未知的，相差一点的贡献可能会带来截然不同的结果。

#### 简谈人工神经网络(Artificial Neural Network ,ANN)

+ 定义：

  ​	受人脑神经系统的工作方式启发而构造的数学模型。

+ 功能：

  ​	可以较好的实现深度学习，是一个不错的`模型`

+ 实现：

  ​	由人工神经元以及神经元之间的连接构成，其中有两类特殊的神经元：

  + 接受外部的信息---输入
  + 输出信息---输出

  通过机器学习的方式，将数据转化为连接神经元之间的参数

#### 人工智能的定义及主要理论

+ 定义：

  ​	人工智能就是要让机器的行为看起来就像是人所表现出的智能行为一样

+ 主要领域：

  + 感知：模拟人的感知能力：语音信息处理和计算机视觉...
  + 学习：模拟人的学习能力：监督学习，无监督学习和强化学习...
  + 认知：模拟人的认知能力：知识表示，自然语言理解，推理，规划，决策...

#### 人工智能的发展历史

1.  推理期：

   基于逻辑或事实归纳，编写对应的程序，从而完成特定的任务---对人工智能的不完全认识导致过于乐观，低估了人工智能的难度

2. 知识期：

   专家系统为这一时期的特色，通过“知识库+推理机”的结构实现解决特定的专业领域的问题

   专家系统的三要素：

   + 领域专家级知识
   + 模拟专家思维
   + 达到专家级的水平

3. 学习期：

   机器学习兴起，让计算机从数据中学习，获得解决问题的方法。机器学习主要就是：设计和分析一些学习算法，让计算机可以从数据中学习经验，从而解决未知的问题

   #### 人工智能的流派

   1. 符号主义：

      + 观点：只要在符号计算上实现了相应的功能，那么现实世界就实现了对应的功能。----只要在机器上是正确的，现实世界也是正确的
      + 成就：专家系统和知识工程
      + 挑战：
        - 知识组合爆炸
        - 命题组合悖论：两个真的命题合起来不一定是真命题
        - 经典概念在实际生活中难以取得

   2. 连接主义：

      + 观点：大脑是一切智能的基础，要关注于大脑神经元及其连接机制，在机器上实现对人脑的模拟

      + 成就: 成为广泛运用的AI实现路线

      + 挑战：对人脑结构的不确定，真正的神经网络和深度学习离现在还有不远的距离

        

   3. 行为主义(书中没有介绍)：

      + 观点：智能只取决于感知和行动，不需要知识，推理和表示，只要将智能行为表现出来就可以了
      + 成就：机器人控制
      + 挑战：`莫拉维克悖论`：对计算机来说，最困难的往往是人类技能中那些无意识的技能



#### 简谈机器学习(Machine Learning,ML )

1. 定义：指从有限的，可观测的数据中学习出具有一般性的规律，并利用这些规律对未知数据进行预测的方法

2. 传统机器学习模型的一般步骤：

   +  数据预处理：对数据的原始形式进行初步的数据清理和加工，构建为训练机器学习模型的数据集

   + 特征提取：从数据中提取一些对特定机器学习任务有用的高质量特征---初加工

   + 特征转换：对特征进行进一步加工----细加工

   + 预测：学习一个函数并进行预测---核心

     ![传统机器学习的数据处理流程](C:\Users\19278\AppData\Roaming\Typora\typora-user-images\image-20210902182003267.png)

#### 表示学习(Representation Learning)

+ 定义：指能够自动地学习出有效的特征，并提高最终机器学习模型地性能
+ 挑战：语义鸿沟(Semantic Gap)问题：指输入数据的底层特征和高层语义信息之间地不一致性和差异性。

+ 问题：1. 什么是好的表示；2. 如何学习到好的表示

常用的两种表示方法：

1. 局部表示----通常表示为one-hot向量的形式
2. 分布式表示

局部表示的优点：

+ 离散的表示方式具有很好的解释性，有利于人工归纳和总结特征，并通过特征组合进行高效的特征工程
+ 通过多种特征组合得到的表示向量通常是稀疏的二值向量，当用于线性模型时计算效率非常高

局部表示的缺点：

+ one-hot向量的维数很高，且不能扩展
+ 不同维度之间的相关性都为0



**分布式表示：**

通过几个较低维度相互组合，可以达到在局部表示中的不同维度的效果。(**嵌入**：指将一个度量空间中的一些对象映射到另一个低维的度量空间中，并尽可能保持不同对象之间的拓扑关系)



#### 深度学习

主要目的：从数据中自动学习到有效的特征表示

深度学习的处理流程：

![image-20211021103533780](C:\Users\19278\AppData\Roaming\Typora\typora-user-images\image-20211021103533780.png)

需要解决的关键问题：贡献度分配问题(Credit Assignment Problem CAP) ，即一个系统中不同的组件或其参数对最终系统输出结果的贡献或影响。

目前深度学习采用的模型主要是**神经网络模型**，主要原因是：神经网络模型可以使用误差反向传播算法，从而可以较好地解决贡献度分配问题



传统机器学习方法：将一个任务切分为多个子模块，每个子模块分开学习。主要的问题：

+ 每个模块都需要单独优化，并且其优化目标和任务总体目标并不能保证一致
+ 错误传播，即前一步的错误会对后续的模型造成很大的影响

端到端学习(端到端训练)：指在学习过程中不进行分模块或分阶段训练，直接优化任务的总体目标。



#### 神经网络

神经网络是指：由很多人工神经元构成的网络结构模型，这些人工神经元之间的连接强度是可学习的参数







